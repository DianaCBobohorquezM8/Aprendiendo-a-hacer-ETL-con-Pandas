# ğŸ¼ MÃ³dulo 3 : Datos de Texto  ğŸ”„
---

# ğŸ§¹ ManipulaciÃ³n de Texto en Pandas y TokenizaciÃ³n

## ğŸ“Œ Â¿Por quÃ© es importante?

* El texto contiene **informaciÃ³n valiosa**, como valoraciones o descripciones que pueden influir en variables como el precio.
* Procesar texto requiere **preparaciÃ³n previa**: limpieza, normalizaciÃ³n y tokenizaciÃ³n.

---

## ğŸ§ª ManipulaciÃ³n de Texto en Pandas

### ğŸ”  ConversiÃ³n a minÃºsculas

Para evitar inconsistencias como "Bonito" vs "bonito", se convierte el texto a minÃºsculas.

```python
df['descripcion'] = df['descripcion'].str.lower()
```

### ğŸ“Œ `.str` y `.lower()`

| MÃ©todo     | FunciÃ³n                                                                 |
| ---------- | ----------------------------------------------------------------------- |
| `.str`     | Accede a mÃ©todos de cadenas en columnas tipo texto (`object`) en Pandas |
| `.lower()` | Convierte todo el texto a minÃºsculas                                    |

---

## âœ‚ï¸ TokenizaciÃ³n: Dividir texto en partes

### âœ… Â¿QuÃ© es tokenizar?

Es dividir un texto en **unidades mÃ¡s pequeÃ±as** llamadas *tokens* (como palabras, caracteres o frases).

---

## ğŸ§° Pasos para Tokenizar un Texto

### 1. Obtener el texto

```python
texto = "Este es un ejemplo de texto para tokenizar."
```

---

### 2. Limpieza del texto (recomendado)

```python
import re

texto = "Â¡Hola! Este es un ejemplo... con sÃ­mbolos."
texto = re.sub(r'[^\w\s]', '', texto)  # Quitar puntuaciÃ³n
texto = texto.lower()  # MinÃºsculas
```

ğŸ” Resultado: `'hola este es un ejemplo con sÃ­mbolos'`

---

### 3. TokenizaciÃ³n por palabras

```python
tokens = texto.split()
print(tokens)
# ['hola', 'este', 'es', 'un', 'ejemplo', 'con', 'sÃ­mbolos']
```

---

### 4. NormalizaciÃ³n

#### ğŸ”¸ Stemming (RaÃ­ces de palabras)

```python
from nltk.stem import PorterStemmer
stemmer = PorterStemmer()
stemmer.stem("running")  # 'run'
```

#### ğŸ”¸ LemmatizaciÃ³n (Forma base)

```python
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
lemmatizer.lemmatize("better")  # 'good'
```

---

### 5. Eliminar Stop Words (palabras comunes)

```python
from nltk.corpus import stopwords
stopwords.words('spanish')  # ['de', 'la', 'que', ...]
```

---

## ğŸ§  Diferencia clave: `apply` vs `applymap`

| MÃ©todo        | Aplica funciÃ³n a...            | Ideal para...            |
| ------------- | ------------------------------ | ------------------------ |
| `.apply()`    | Cada valor de una **Serie**    | Una sola columna         |
| `.applymap()` | Cada valor de un **DataFrame** | Varias columnas a la vez |

---

## ğŸ’¡ Ejemplos rÃ¡pidos

### â• `apply()` â€“ elevar al cuadrado

```python
s = pd.Series([1, 2, 3])
s.apply(lambda x: x**2)
```

### â• `applymap()` â€“ sumar 10 a cada valor

```python
df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
df.applymap(lambda x: x + 10)
```

---
## ğŸ§  Â¿QuÃ© son las Expresiones Regulares (Regex)?

**Regex (Regular Expressions)** son patrones que se utilizan para buscar, extraer o reemplazar texto dentro de cadenas. Son una herramienta esencial para **limpiar, normalizar o validar** texto en tareas de anÃ¡lisis de datos, especialmente cuando los datos provienen de fuentes no estructuradas como formularios, correos o redes sociales.

---

## ğŸ“Œ Â¿Para quÃ© sirven en ciencia de datos?

* **Limpieza de texto** (eliminaciÃ³n de sÃ­mbolos, puntuaciÃ³n, etiquetas HTML, etc.)
* **ExtracciÃ³n de patrones** (como emails, fechas, precios, etc.)
* **ValidaciÃ³n de formatos** (por ejemplo, verificar que una cadena sea un cÃ³digo postal vÃ¡lido)
* **ClasificaciÃ³n** (spam/no spam, sentimientos, categorÃ­as)

---

## ğŸ§ª Metacaracteres comunes en Regex

| SÃ­mbolo | Significado                                                  |                   |      |
| ------- | ------------------------------------------------------------ | ----------------- | ---- |
| `.`     | Cualquier carÃ¡cter (excepto salto de lÃ­nea)                  |                   |      |
| `*`     | Cero o mÃ¡s repeticiones                                      |                   |      |
| `+`     | Una o mÃ¡s repeticiones                                       |                   |      |
| `?`     | Cero o una repeticiÃ³n                                        |                   |      |
| `[]`    | Conjunto de caracteres (ej: `[abc]`)                         |                   |      |
| `[^]`   | NegaciÃ³n del conjunto (ej: `[^abc]`)                         |                   |      |
| `()`    | AgrupaciÃ³n de patrones                                       |                   |      |
| \`      | \`                                                           | O lÃ³gico (ej: \`a | b\`) |
| `\`     | Escape de carÃ¡cter especial (ej: `\.` para un punto literal) |                   |      |
| `^`     | Inicio de lÃ­nea                                              |                   |      |
| `$`     | Fin de lÃ­nea                                                 |                   |      |

---

## ğŸ›  MÃ©todos clave en Python/Pandas para manipulaciÃ³n de texto

### 1. `.str.replace()` en Pandas

Permite reemplazar texto en una columna entera.

**Ejemplo bÃ¡sico:**

```python
df['columna'] = df['columna'].str.replace('malo', 'bueno')
```

**Ejemplo con regex:**

```python
df['columna'] = df['columna'].str.replace(r'\d+', '', regex=True)  # Elimina todos los nÃºmeros
```

---

### 2. `.str.strip()`

Elimina espacios en blanco al principio y al final de una cadena.

```python
texto = "  hola mundo  "
print(texto.strip())  # â†’ "hola mundo"
```

---

## ğŸ§¹ EliminaciÃ³n de guiones aislados con Regex

Cuando limpiamos texto, es Ãºtil eliminar guiones que **no estÃ¡n entre palabras** (por ejemplo: al final de una lÃ­nea o aislados).

### ğŸ” Regex usada:

```regex
(?<!\w)-(?!\w)
```

### Desglose:

* `(?<!\w)`: Negative lookbehind â†’ **no debe haber una letra o nÃºmero antes del guiÃ³n**
* `-`: Coincide con el guiÃ³n literal
* `(?!\w)`: Negative lookahead â†’ **no debe haber una letra o nÃºmero despuÃ©s del guiÃ³n**

**Ejemplo en Pandas:**

```python
df['columna'] = df['columna'].str.replace(r'(?<!\w)-(?!\w)', '', regex=True).str.strip()
```

---

## ğŸ”¤ TokenizaciÃ³n de Texto

Es el proceso de **dividir texto en unidades (tokens)** como palabras o frases.

**Ejemplo en Python:**

```python
texto = "Hola mundo, esto es NLP"
tokens = texto.lower().split()
print(tokens)  # ['hola', 'mundo,', 'esto', 'es', 'nlp']
```

---

## ğŸ§° Limpieza de texto avanzada con `re` (mÃ³dulo de expresiones regulares de Python)

### Ejemplo completo:

```python
import re

texto = "Â¡Hola! Este es un ejemplo - con sÃ­mbolos y nÃºmeros 123."

# Eliminar caracteres especiales
texto = re.sub(r'[^\w\s]', '', texto)   # â†’ 'Hola Este es un ejemplo  con sÃ­mbolos y nÃºmeros 123'

# Convertir a minÃºsculas
texto = texto.lower()

# Eliminar nÃºmeros
texto = re.sub(r'\d+', '', texto)       # â†’ 'hola este es un ejemplo  con sÃ­mbolos y nÃºmeros '

# Eliminar espacios mÃºltiples
texto = re.sub(r'\s+', ' ', texto).strip()

print(texto)  # â†’ 'hola este es un ejemplo con sÃ­mbolos y nÃºmeros'
```

---

## ğŸš« Stop Words

Son palabras que aparecen frecuentemente pero no aportan valor al anÃ¡lisis (como â€œelâ€, â€œdeâ€, â€œporâ€, â€œconâ€).

**Ejemplo con NLTK:**

```python
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk
nltk.download('stopwords')
nltk.download('punkt')

texto = "Este es un ejemplo de texto con stop words"
palabras = word_tokenize(texto.lower())
limpio = [palabra for palabra in palabras if palabra not in stopwords.words('spanish')]

print(limpio)  # â†’ ['ejemplo', 'texto', 'stop', 'words']
```

---

## ğŸ§± Conceptos clave resumidos

| Concepto             | DescripciÃ³n                                          |
| -------------------- | ---------------------------------------------------- |
| **TokenizaciÃ³n**     | Dividir texto en unidades (palabras, frases, etc.)   |
| **Regex**            | PatrÃ³n para buscar, extraer o reemplazar texto       |
| **replace()**        | Reemplaza partes de una cadena                       |
| **strip()**          | Elimina espacios en extremos de una cadena           |
| **Guiones aislados** | Guiones sin letras alrededor (eliminables con regex) |
| **Stop words**       | Palabras vacÃ­as que no aportan valor                 |
| **NormalizaciÃ³n**    | Unificar el texto (minÃºsculas, sin puntuaciÃ³n, etc.) |

---
### ğŸ§¹ **Limpieza de texto con expresiones regulares en Pandas**

#### ğŸ› ï¸ **Â¿QuÃ© hicimos?**

Se aplicaron expresiones regulares (regex) sobre la columna `descripciÃ³n_local` para limpiar el texto:

#### 1ï¸âƒ£ **Eliminar caracteres especiales (excepto letras, nÃºmeros, guiones y comillas simples)**

```python
datos['descripciÃ³n_local'] = datos['descripciÃ³n_local'].str.replace('[^a-zA-Z0-9\-\' ]', ' ', regex=True)
```

##### âœ”ï¸ Â¿QuÃ© hace esta expresiÃ³n?

* Reemplaza cualquier carÃ¡cter que **no** sea:

  * Letras minÃºsculas (`a-z`)
  * Letras mayÃºsculas (`A-Z`)
  * NÃºmeros (`0-9`)
  * Guiones (`-`)
  * Comillas simples (`'`)
  * Espacios (` `)
* Los caracteres encontrados se reemplazan por un espacio.

##### ğŸ” ExplicaciÃ³n de la regex:

* `[^...]`: busca todo lo que **no** estÃ© dentro del conjunto.
* `a-zA-Z0-9\-\'`: los caracteres permitidos (notar el uso de `\` para escapar `-` y `'`).
* `regex=True`: indica que `pat` es una expresiÃ³n regular.

---

#### 2ï¸âƒ£ **Eliminar guiones que estÃ©n aislados (no rodeados por letras o nÃºmeros)**

```python
datos['descripciÃ³n_local'] = datos['descripciÃ³n_local'].str.replace(r'(\W|^)-(\W|$)', ' ', regex=True)
```

##### âœ”ï¸ Â¿QuÃ© hace esta expresiÃ³n?

* Busca guiones que:

  * EstÃ¡n al inicio o fin de cadena (`^`, \`\$)
  * O estÃ¡n rodeados por caracteres no alfanumÃ©ricos (`\W`)

##### ğŸ” ExplicaciÃ³n:

* `(\W|^)`: carÃ¡cter no alfanumÃ©rico o inicio de cadena.
* `-`: guion literal.
* `(\W|$)`: carÃ¡cter no alfanumÃ©rico o fin de cadena.

---

### ğŸ” **Conceptos clave de regex**

| SÃ­mbolo | Significado                                                  |            |
| ------- | ------------------------------------------------------------ | ---------- |
| `[]`    | Conjunto de caracteres permitidos                            |            |
| `^`     | NegaciÃ³n (dentro de `[]`) o inicio de cadena (fuera de `[]`) |            |
| `\W`    | Cualquier carÃ¡cter que **no** sea alfanumÃ©rico               |            |
| `\s`    | Espacio en blanco                                            |            |
| `$`     | Fin de cadena                                                |            |
| \`      | \`                                                           | "O" lÃ³gico |
| `\`     | Escapa caracteres especiales                                 |            |

---

### ğŸ§  **MÃ©todos importantes en Pandas**

#### `str.replace(pat, repl, regex=True)`

* Reemplaza valores que coincidan con un patrÃ³n.
* `pat`: el patrÃ³n a buscar.
* `repl`: el valor nuevo.
* `regex=True`: indica que `pat` es una expresiÃ³n regular.

#### `str.strip()`

* Elimina espacios al inicio y final de la cadena.
* Ãštil luego de aplicar `.replace()`.

---

### ğŸ’¡ **Ejemplo prÃ¡ctico**

```python
import pandas as pd

texto = pd.Series(["Â¡Hola, mundo! 123. Â¿CÃ³mo estÃ¡s?"])
texto_limpio = texto.str.replace('[^a-zA-Z0-9\s]', '', regex=True)

print(texto_limpio[0])  # Output: Holamundo 123 CÃ³moestÃ¡s
```

---

### ğŸ“Œ **Resumen**

* **Regex** permite definir patrones complejos para limpiar texto automÃ¡ticamente.
* Es ideal para tareas de **preprocesamiento de texto**, fundamentales en **anÃ¡lisis de datos** y **NLP** (procesamiento de lenguaje natural).
* Usar mÃ©todos como `.str.replace()` con `regex=True` permite personalizar la limpieza.
* Los mÃ©todos `.apply()` y `.applymap()` tambiÃ©n ayudan a aplicar funciones personalizadas a columnas o DataFrames completos.

---

