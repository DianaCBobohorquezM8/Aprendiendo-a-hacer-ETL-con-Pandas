# ğŸ¼ MÃ³dulo 3 : Datos de Texto  ğŸ”„
---

# ğŸ§¹ ManipulaciÃ³n de Texto en Pandas y TokenizaciÃ³n

## ğŸ“Œ Â¿Por quÃ© es importante?

* El texto contiene **informaciÃ³n valiosa**, como valoraciones o descripciones que pueden influir en variables como el precio.
* Procesar texto requiere **preparaciÃ³n previa**: limpieza, normalizaciÃ³n y tokenizaciÃ³n.

---

## ğŸ§ª ManipulaciÃ³n de Texto en Pandas

### ğŸ”  ConversiÃ³n a minÃºsculas

Para evitar inconsistencias como "Bonito" vs "bonito", se convierte el texto a minÃºsculas.

```python
df['descripcion'] = df['descripcion'].str.lower()
```

### ğŸ“Œ `.str` y `.lower()`

| MÃ©todo     | FunciÃ³n                                                                 |
| ---------- | ----------------------------------------------------------------------- |
| `.str`     | Accede a mÃ©todos de cadenas en columnas tipo texto (`object`) en Pandas |
| `.lower()` | Convierte todo el texto a minÃºsculas                                    |

---

## âœ‚ï¸ TokenizaciÃ³n: Dividir texto en partes

### âœ… Â¿QuÃ© es tokenizar?

Es dividir un texto en **unidades mÃ¡s pequeÃ±as** llamadas *tokens* (como palabras, caracteres o frases).

---

## ğŸ§° Pasos para Tokenizar un Texto

### 1. Obtener el texto

```python
texto = "Este es un ejemplo de texto para tokenizar."
```

---

### 2. Limpieza del texto (recomendado)

```python
import re

texto = "Â¡Hola! Este es un ejemplo... con sÃ­mbolos."
texto = re.sub(r'[^\w\s]', '', texto)  # Quitar puntuaciÃ³n
texto = texto.lower()  # MinÃºsculas
```

ğŸ” Resultado: `'hola este es un ejemplo con sÃ­mbolos'`

---

### 3. TokenizaciÃ³n por palabras

```python
tokens = texto.split()
print(tokens)
# ['hola', 'este', 'es', 'un', 'ejemplo', 'con', 'sÃ­mbolos']
```

---

### 4. NormalizaciÃ³n

#### ğŸ”¸ Stemming (RaÃ­ces de palabras)

```python
from nltk.stem import PorterStemmer
stemmer = PorterStemmer()
stemmer.stem("running")  # 'run'
```

#### ğŸ”¸ LemmatizaciÃ³n (Forma base)

```python
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
lemmatizer.lemmatize("better")  # 'good'
```

---

### 5. Eliminar Stop Words (palabras comunes)

```python
from nltk.corpus import stopwords
stopwords.words('spanish')  # ['de', 'la', 'que', ...]
```

---

## ğŸ§  Diferencia clave: `apply` vs `applymap`

| MÃ©todo        | Aplica funciÃ³n a...            | Ideal para...            |
| ------------- | ------------------------------ | ------------------------ |
| `.apply()`    | Cada valor de una **Serie**    | Una sola columna         |
| `.applymap()` | Cada valor de un **DataFrame** | Varias columnas a la vez |

---

## ğŸ’¡ Ejemplos rÃ¡pidos

### â• `apply()` â€“ elevar al cuadrado

```python
s = pd.Series([1, 2, 3])
s.apply(lambda x: x**2)
```

### â• `applymap()` â€“ sumar 10 a cada valor

```python
df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
df.applymap(lambda x: x + 10)
```

---
## ğŸ§  Â¿QuÃ© son las Expresiones Regulares (Regex)?

**Regex (Regular Expressions)** son patrones que se utilizan para buscar, extraer o reemplazar texto dentro de cadenas. Son una herramienta esencial para **limpiar, normalizar o validar** texto en tareas de anÃ¡lisis de datos, especialmente cuando los datos provienen de fuentes no estructuradas como formularios, correos o redes sociales.

---

## ğŸ“Œ Â¿Para quÃ© sirven en ciencia de datos?

* **Limpieza de texto** (eliminaciÃ³n de sÃ­mbolos, puntuaciÃ³n, etiquetas HTML, etc.)
* **ExtracciÃ³n de patrones** (como emails, fechas, precios, etc.)
* **ValidaciÃ³n de formatos** (por ejemplo, verificar que una cadena sea un cÃ³digo postal vÃ¡lido)
* **ClasificaciÃ³n** (spam/no spam, sentimientos, categorÃ­as)

---
### ğŸ§ª Metacaracteres comunes en Regex

| SÃ­mbolo | Significado                                                                 |
|---------|------------------------------------------------------------------------------|
| `.`     | Cualquier carÃ¡cter (excepto salto de lÃ­nea)                                 |
| `*`     | Cero o mÃ¡s repeticiones del carÃ¡cter o grupo anterior                       |
| `+`     | Una o mÃ¡s repeticiones del carÃ¡cter o grupo anterior                        |
| `?`     | Cero o una repeticiÃ³n del carÃ¡cter o grupo anterior                         |
| `[]`    | Conjunto de caracteres (ej: `[abc]` busca "a", "b" o "c")                   |
| `[^]`   | NegaciÃ³n del conjunto (ej: `[^abc]` busca cualquier carÃ¡cter excepto "a,b,c")|
| `()`    | AgrupaciÃ³n de patrones (para capturar o aplicar operadores)                 |
| `\|`    | O lÃ³gico (ej: `a\|b` coincide con "a" o "b")                                 |
| `\`     | Escape de carÃ¡cter especial (ej: `\.` busca un punto literal)               |
| `^`     | Inicio de lÃ­nea                                                              |
| `$`     | Fin de lÃ­nea                                                                 |


---

## ğŸ›  MÃ©todos clave en Python/Pandas para manipulaciÃ³n de texto

### 1. `.str.replace()` en Pandas

Permite reemplazar texto en una columna entera.

**Ejemplo bÃ¡sico:**

```python
df['columna'] = df['columna'].str.replace('malo', 'bueno')
```

**Ejemplo con regex:**

```python
df['columna'] = df['columna'].str.replace(r'\d+', '', regex=True)  # Elimina todos los nÃºmeros
```

---

### 2. `.str.strip()`

Elimina espacios en blanco al principio y al final de una cadena.

```python
texto = "  hola mundo  "
print(texto.strip())  # â†’ "hola mundo"
```

---

## ğŸ§¹ EliminaciÃ³n de guiones aislados con Regex

Cuando limpiamos texto, es Ãºtil eliminar guiones que **no estÃ¡n entre palabras** (por ejemplo: al final de una lÃ­nea o aislados).

### ğŸ” Regex usada:

```regex
(?<!\w)-(?!\w)
```

### Desglose:

* `(?<!\w)`: Negative lookbehind â†’ **no debe haber una letra o nÃºmero antes del guiÃ³n**
* `-`: Coincide con el guiÃ³n literal
* `(?!\w)`: Negative lookahead â†’ **no debe haber una letra o nÃºmero despuÃ©s del guiÃ³n**

**Ejemplo en Pandas:**

```python
df['columna'] = df['columna'].str.replace(r'(?<!\w)-(?!\w)', '', regex=True).str.strip()
```

---

## ğŸ”¤ TokenizaciÃ³n de Texto

Es el proceso de **dividir texto en unidades (tokens)** como palabras o frases.

**Ejemplo en Python:**

```python
texto = "Hola mundo, esto es NLP"
tokens = texto.lower().split()
print(tokens)  # ['hola', 'mundo,', 'esto', 'es', 'nlp']
```

---

## ğŸ§° Limpieza de texto avanzada con `re` (mÃ³dulo de expresiones regulares de Python)

### Ejemplo completo:

```python
import re

texto = "Â¡Hola! Este es un ejemplo - con sÃ­mbolos y nÃºmeros 123."

# Eliminar caracteres especiales
texto = re.sub(r'[^\w\s]', '', texto)   # â†’ 'Hola Este es un ejemplo  con sÃ­mbolos y nÃºmeros 123'

# Convertir a minÃºsculas
texto = texto.lower()

# Eliminar nÃºmeros
texto = re.sub(r'\d+', '', texto)       # â†’ 'hola este es un ejemplo  con sÃ­mbolos y nÃºmeros '

# Eliminar espacios mÃºltiples
texto = re.sub(r'\s+', ' ', texto).strip()

print(texto)  # â†’ 'hola este es un ejemplo con sÃ­mbolos y nÃºmeros'
```

---

## ğŸš« Stop Words

Son palabras que aparecen frecuentemente pero no aportan valor al anÃ¡lisis (como â€œelâ€, â€œdeâ€, â€œporâ€, â€œconâ€).

**Ejemplo con NLTK:**

```python
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk
nltk.download('stopwords')
nltk.download('punkt')

texto = "Este es un ejemplo de texto con stop words"
palabras = word_tokenize(texto.lower())
limpio = [palabra for palabra in palabras if palabra not in stopwords.words('spanish')]

print(limpio)  # â†’ ['ejemplo', 'texto', 'stop', 'words']
```

---

## ğŸ§± Conceptos clave resumidos

| Concepto             | DescripciÃ³n                                          |
| -------------------- | ---------------------------------------------------- |
| **TokenizaciÃ³n**     | Dividir texto en unidades (palabras, frases, etc.)   |
| **Regex**            | PatrÃ³n para buscar, extraer o reemplazar texto       |
| **replace()**        | Reemplaza partes de una cadena                       |
| **strip()**          | Elimina espacios en extremos de una cadena           |
| **Guiones aislados** | Guiones sin letras alrededor (eliminables con regex) |
| **Stop words**       | Palabras vacÃ­as que no aportan valor                 |
| **NormalizaciÃ³n**    | Unificar el texto (minÃºsculas, sin puntuaciÃ³n, etc.) |

---
### ğŸ§¹ **Limpieza de texto con expresiones regulares en Pandas**

#### ğŸ› ï¸ **Â¿QuÃ© hicimos?**

Se aplicaron expresiones regulares (regex) sobre la columna `descripciÃ³n_local` para limpiar el texto:

#### 1ï¸âƒ£ **Eliminar caracteres especiales (excepto letras, nÃºmeros, guiones y comillas simples)**

```python
datos['descripciÃ³n_local'] = datos['descripciÃ³n_local'].str.replace('[^a-zA-Z0-9\-\' ]', ' ', regex=True)
```

##### âœ”ï¸ Â¿QuÃ© hace esta expresiÃ³n?

* Reemplaza cualquier carÃ¡cter que **no** sea:

  * Letras minÃºsculas (`a-z`)
  * Letras mayÃºsculas (`A-Z`)
  * NÃºmeros (`0-9`)
  * Guiones (`-`)
  * Comillas simples (`'`)
  * Espacios (` `)
* Los caracteres encontrados se reemplazan por un espacio.

##### ğŸ” ExplicaciÃ³n de la regex:

* `[^...]`: busca todo lo que **no** estÃ© dentro del conjunto.
* `a-zA-Z0-9\-\'`: los caracteres permitidos (notar el uso de `\` para escapar `-` y `'`).
* `regex=True`: indica que `pat` es una expresiÃ³n regular.

---

#### 2ï¸âƒ£ **Eliminar guiones que estÃ©n aislados (no rodeados por letras o nÃºmeros)**

```python
datos['descripciÃ³n_local'] = datos['descripciÃ³n_local'].str.replace(r'(\W|^)-(\W|$)', ' ', regex=True)
```

##### âœ”ï¸ Â¿QuÃ© hace esta expresiÃ³n?

* Busca guiones que:

  * EstÃ¡n al inicio o fin de cadena (`^`, \`\$)
  * O estÃ¡n rodeados por caracteres no alfanumÃ©ricos (`\W`)

##### ğŸ” ExplicaciÃ³n:

* `(\W|^)`: carÃ¡cter no alfanumÃ©rico o inicio de cadena.
* `-`: guion literal.
* `(\W|$)`: carÃ¡cter no alfanumÃ©rico o fin de cadena.

---
### ğŸ” **Conceptos clave de regex**

| SÃ­mbolo | Significado                                                  | Ejemplo o nota adicional         |
| ------- | ------------------------------------------------------------ | -------------------------------- |
| `[]`    | Conjunto de caracteres permitidos                            | `[abc]` coincide con 'a', 'b', 'c' |
| `^`     | NegaciÃ³n (dentro de `[]`) o inicio de cadena (fuera de `[]`) | `[^abc]` o `^Hola`               |
| `\W`    | Cualquier carÃ¡cter que **no** sea alfanumÃ©rico               | Coincide con sÃ­mbolos como `@` o `#` |
| `\s`    | Espacio en blanco                                            | Incluye espacios, tabs, saltos de lÃ­nea |
| `$`     | Fin de cadena                                                | `mundo$` coincide con "Hola mundo" |
| `\|`     | â€œOâ€ lÃ³gico                                                    | `promo\|descuento`                |
| `\`     | Escapa caracteres especiales                                 | `\.` busca un punto literal      |

---

### ğŸ§  **MÃ©todos importantes en Pandas**

#### `str.replace(pat, repl, regex=True)`

* Reemplaza valores que coincidan con un patrÃ³n.
* `pat`: el patrÃ³n a buscar.
* `repl`: el valor nuevo.
* `regex=True`: indica que `pat` es una expresiÃ³n regular.

#### `str.strip()`

* Elimina espacios al inicio y final de la cadena.
* Ãštil luego de aplicar `.replace()`.

---

### ğŸ’¡ **Ejemplo prÃ¡ctico**

```python
import pandas as pd

texto = pd.Series(["Â¡Hola, mundo! 123. Â¿CÃ³mo estÃ¡s?"])
texto_limpio = texto.str.replace('[^a-zA-Z0-9\s]', '', regex=True)

print(texto_limpio[0])  # Output: Holamundo 123 CÃ³moestÃ¡s
```

---

### ğŸ“Œ **Resumen**

* **Regex** permite definir patrones complejos para limpiar texto automÃ¡ticamente.
* Es ideal para tareas de **preprocesamiento de texto**, fundamentales en **anÃ¡lisis de datos** y **NLP** (procesamiento de lenguaje natural).
* Usar mÃ©todos como `.str.replace()` con `regex=True` permite personalizar la limpieza.
* Los mÃ©todos `.apply()` y `.applymap()` tambiÃ©n ayudan a aplicar funciones personalizadas a columnas o DataFrames completos.

---
## ğŸ§© Â¿QuÃ© son las Expresiones Regulares (Regex)?

**Regex** (del inglÃ©s *regular expressions*) es una **secuencia de caracteres especiales** que define un **patrÃ³n de bÃºsqueda** dentro de un texto. Es una herramienta poderosa que permite:

* Buscar coincidencias en cadenas.
* Reemplazar fragmentos de texto.
* Extraer o validar informaciÃ³n estructurada.
* Limpiar datos de forma automatizada.

---

## ğŸ§ª Aplicaciones en Ciencia de Datos

### ğŸ”¹ **1. Limpieza de datos**

* **Eliminar sÃ­mbolos no deseados** como `$`, `%`, `#`, etc.
* **Normalizar texto**, por ejemplo, convertir a minÃºsculas o eliminar espacios dobles.

```python
df['columna'] = df['columna'].str.replace('[^a-zA-Z0-9 ]', '', regex=True)
```

### ğŸ”¹ **2. ExtracciÃ³n de informaciÃ³n**

* Extraer **nÃºmeros de telÃ©fono**, **correos electrÃ³nicos**, **fechas**, etc., desde texto sin estructurar.

```python
# Buscar correos en una columna
df['email'] = df['texto'].str.extract(r'[\w\.-]+@[\w\.-]+\.\w+')
```

### ğŸ”¹ **3. ClasificaciÃ³n de texto**

* Detectar **patrones repetitivos** que indiquen si un correo es *spam*.
* Buscar palabras clave especÃ­ficas en reseÃ±as, publicaciones o mensajes.

```python
df['spam'] = df['mensaje'].str.contains(r'(gratis|oferta|haz clic aquÃ­)', case=False)
```

---

## ğŸ§  Ventajas del uso de Regex en Ciencia de Datos

| Ventaja                        | DescripciÃ³n                                                                                     |
| ------------------------------ | ----------------------------------------------------------------------------------------------- |
| ğŸ” BÃºsqueda avanzada           | Permite identificar patrones complejos que un simple `.contains()` no podrÃ­a.                   |
| âš™ï¸ AutomatizaciÃ³n              | Facilita la limpieza masiva de texto sin necesidad de bucles.                                   |
| ğŸ“Š Mejora del anÃ¡lisis textual | Ayuda a preprocesar datos antes de aplicar algoritmos de NLP o Machine Learning.                |
| ğŸ” ValidaciÃ³n de datos         | Puedes verificar si una cadena cumple con un formato (como una cÃ©dula, correo o cÃ³digo postal). |

---

## âœï¸ Ejemplos Ãºtiles

| Objetivo                       | Regex                           | DescripciÃ³n                                        |
|-------------------------------|----------------------------------|----------------------------------------------------|
| Eliminar caracteres especiales| `[^a-zA-Z0-9 ]`                  | Todo lo que no sea letra, nÃºmero o espacio.        |
| Extraer dÃ­gitos               | `\d+`                            | Uno o mÃ¡s dÃ­gitos seguidos.                        |
| Detectar correos electrÃ³nicos| `[\w\.-]+@[\w\.-]+\.\w+`         | Coincide con correos electrÃ³nicos bÃ¡sicos.         |
| Palabras especÃ­ficas          | `\b(promo|descuento)\b`         | Detecta palabras exactas "promo" o "descuento".    |

âœ… **Notas**:

* Los sÃ­mbolos `\b` indican **lÃ­mites de palabra**, para que no detecte partes de otras palabras (por ejemplo, "promocionar").
* Todo estÃ¡ alineado para que se vea bien tanto en editores Markdown como en Jupyter Notebooks.
---
## ğŸ§  Â¿DÃ³nde se aplica Regex?

Las expresiones regulares (Regex) se utilizan ampliamente para buscar, validar, extraer o modificar cadenas de texto en diversas Ã¡reas. A continuaciÃ³n, se presentan algunos ejemplos comunes:

---

### 1. ğŸ” **Consultas en bases de datos**

Regex puede usarse en motores de bases de datos compatibles para realizar bÃºsquedas avanzadas.

```sql
SELECT * FROM filmes WHERE titulo REGEXP '^[era uma vez]';
```

**ExplicaciÃ³n:**

* `^`: indica que la coincidencia debe comenzar al inicio de la cadena.
* `[era uma vez]`: esta notaciÃ³n estÃ¡ incorrecta para expresar â€œera una vezâ€. AquÃ­ se estÃ¡ buscando tÃ­tulos que empiecen con cualquiera de los caracteres `e`, `r`, `a`, etc.
  âœ”ï¸ **Forma correcta esperada**: `'^(era|uma|vez)'`

---

### 2. âœ… **ValidaciÃ³n de entradas (Java)**

Regex es Ãºtil para validar correos electrÃ³nicos, contraseÃ±as, nÃºmeros, etc.

```java
private void setEmail(String email) {
    String regex = "^[A-Za-z0-9+_.-]+@(.+)$";
    if (!email.matches(regex)) {
        throw new IllegalArgumentException("Email InvÃ¡lido!");
    }
    this.email = email;
}
```

**ExplicaciÃ³n:**

* `^[A-Za-z0-9+_.-]+`: permite letras, nÃºmeros y sÃ­mbolos comunes antes del `@`.
* `@(.+)$`: garantiza que despuÃ©s del `@` haya al menos un carÃ¡cter.

---

### 3. ğŸ§¾ **ExtracciÃ³n de datos (ejemplo: CPF brasileÃ±o)**

```regex
[0-9]{3}\.?[0-9]{3}\.?[0-9]{3}\-?[0-9]{2}
```

**ExplicaciÃ³n:**

* `[0-9]{3}`: tres dÃ­gitos numÃ©ricos.
* `\.?`: punto opcional (el `\` escapa el punto).
* `\-?`: guion opcional.
* Esta expresiÃ³n busca coincidencias como `123.456.789-00`.

---

### 4. ğŸ“Š **Procesamiento de datos (Ejemplo: Tableau)**

#### ğŸ§© a) `REGEXP_REPLACE(cadena, patrÃ³n, reemplazo)`

Reemplaza caracteres segÃºn un patrÃ³n.

```text
REGEXP_REPLACE([categoria_produto], '[0-9]|[-]|[_]', ' ')
```

**Objetivo:** Eliminar nÃºmeros, guiones y guiones bajos, reemplazÃ¡ndolos por espacios.

#### ğŸ§ª b) `REGEXP_MATCH(cadena, patrÃ³n)`

Devuelve `TRUE` si la cadena coincide con el patrÃ³n, `FALSE` si no.

```text
REGEXP_MATCH([categoria], '([0-9])')
```

**Objetivo:** Verificar si hay al menos un dÃ­gito en el campo `categoria`.

#### ğŸ§¬ c) `REGEXP_EXTRACT(cadena, patrÃ³n)`

Extrae parte de la cadena que coincida con un patrÃ³n.

```text
REGEXP_EXTRACT([categoria_produto], '(\d+)')
```

**Objetivo:** Extraer el nÃºmero de identificaciÃ³n (`id`) que aparece al inicio del texto (como `1-` en `1-agro_industria`).

---

## âœ… Resumen

| AplicaciÃ³n                 | Herramienta/funciÃ³n                  | DescripciÃ³n breve                                         |
| -------------------------- | ------------------------------------ | --------------------------------------------------------- |
| Consultas SQL              | `REGEXP`                             | Filtra registros por patrones de texto                    |
| ValidaciÃ³n en cÃ³digo Java  | `String.matches(regex)`              | Verifica si una cadena cumple con el formato esperado     |
| ExtracciÃ³n en datos crudos | Regex manual o con herramientas      | Identifica patrones como nÃºmeros, fechas o correos        |
| Procesamiento en Tableau   | `REGEXP_REPLACE`, `MATCH`, `EXTRACT` | Limpia, verifica o extrae valores especÃ­ficos en columnas |

---
# âœ‚ï¸ Transformar textos en listas (TokenizaciÃ³n en Pandas)

La **tokenizaciÃ³n** es el proceso de dividir una cadena de texto en unidades mÃ¡s pequeÃ±as llamadas **tokens**, que suelen ser palabras, frases o sÃ­mbolos.
En **ciencia de datos**, la tokenizaciÃ³n es fundamental para preparar texto antes de anÃ¡lisis o modelado.

---

## ğŸ”‘ Conceptos Clave

| Concepto                          | DefiniciÃ³n                                                                              |
| --------------------------------- | --------------------------------------------------------------------------------------- |
| **TokenizaciÃ³n**                  | Proceso de dividir texto en unidades mÃ¡s pequeÃ±as (palabras, frases, sÃ­mbolos).         |
| **Strings (cadenas)**             | Secuencias de caracteres que representan texto. En Pandas, se manejan con `Series.str`. |
| **Regex (Expresiones regulares)** | Patrones que permiten buscar, limpiar y manipular texto de forma flexible.              |

---

## ğŸ› ï¸ MÃ©todos Utilizados en Pandas

| MÃ©todo                                | FunciÃ³n                                                                                        | Ejemplo                                     |
| ------------------------------------- | ---------------------------------------------------------------------------------------------- | ------------------------------------------- |
| `.str.split(sep)`                     | Divide el texto en una lista de tokens usando un separador (por defecto espacio).              | `"hola mundo".split()` â†’ `['hola','mundo']` |
| `.str.replace(pat, repl, regex=True)` | Reemplaza partes de un texto segÃºn un patrÃ³n regex. Ãštil para eliminar caracteres no deseados. | `texto.str.replace('[{}"]','',regex=True)`  |

---

## âš™ï¸ Ejemplo prÃ¡ctico en Pandas

Supongamos que tenemos un DataFrame con una columna de descripciones:

```python
import pandas as pd

data = {'descripcion': ["Este es un ejemplo de frase con algunas palabras."]}
df = pd.DataFrame(data)

# TokenizaciÃ³n por espacios
df['descripcion_tokenizada'] = df['descripcion'].str.split()

print(df)
```

### âœ… Resultado:

| descripcion                                         | descripcion\_tokenizada                                                        |
| --------------------------------------------------- | ------------------------------------------------------------------------------ |
| "Este es un ejemplo de frase con algunas palabras." | \['Este', 'es', 'un', 'ejemplo', 'de', 'frase', 'con', 'algunas', 'palabras.'] |

---

## ğŸ§¹ Limpieza con Regex antes de tokenizar

Si el texto contiene **caracteres no deseados** como `{}`, `"` o puntuaciÃ³n, podemos limpiarlo primero:

```python
df['descripcion_limpia'] = df['descripcion'].str.replace('[{}"]', '', regex=True)
df['descripcion_tokenizada'] = df['descripcion_limpia'].str.split()
```

Esto genera una columna **limpia** y luego la **lista de tokens** sin caracteres especiales.

---

## ğŸ“Œ Variantes de TokenizaciÃ³n

1. **SeparaciÃ³n por espacios (default):**

   ```python
   df['columna'].str.split()
   ```

   â†’ Divide en palabras por espacio.

2. **SeparaciÃ³n por comas:**

   ```python
   df['columna'].str.split(',')
   ```

   â†’ Ãštil si tenemos listas tipo `"python,pandas,numpy"`.

3. **Regex como separador:**

   ```python
   df['columna'].str.split('[,;.]')
   ```

   â†’ Divide usando comas, punto y coma o punto.

---
## ğŸ“ Apunte: Limpieza de texto con Regex en Pandas

### ğŸ”¹ Problema

Algunas columnas tienen texto extra dentro de parÃ©ntesis, por ejemplo:

```
A101 (blocoAP)
A102 (blocoAP)
```

y necesitamos eliminar esa parte.

---

### ğŸ”¹ Errores comunes

1. **ParÃ©ntesis en regex**
   Los `()` son grupos en regex, por eso se deben **escapar** con `\(` y `\)`.
   Ejemplo: `\(blocoAP\)` busca exactamente `(blocoAP)`.

2. **Uso de `\` en Python**
   En Python, la barra invertida tambiÃ©n es especial.
   Para evitar problemas, usamos **raw strings** (`r''`).
   Ejemplo: `r'\(blocoAP\)'`.

3. **Espacios alrededor**
   En los datos aparece `" (blocoAP)"`, no solo `"(blocoAP)"`.
   Por eso conviene incluir el espacio en el patrÃ³n.

---

### ğŸ”¹ SoluciÃ³n

CÃ³digo para eliminar `" (blocoAP)"` de la columna:

```python
datos2['apartamento'] = datos2['apartamento'].str.replace(r'\s*\(blocoAP\)', '', regex=True)
```

âœ… ExplicaciÃ³n del patrÃ³n:

* `\s*` â†’ cero o mÃ¡s espacios antes.
* `\(blocoAP\)` â†’ literal `(blocoAP)`.

---

### ğŸ”¹ Extra (mÃ¡s general)

Si quieres eliminar **cualquier cosa entre parÃ©ntesis**, usa:

```python
datos2['apartamento'] = datos2['apartamento'].str.replace(r'\s*\(.*?\)', '', regex=True)
```

ğŸ‘‰ `.*?` significa â€œcualquier cosaâ€ dentro de los parÃ©ntesis.

---

ğŸ“Œ **Resultado esperado**:

```
A101
A101
A102
A102
```

---
