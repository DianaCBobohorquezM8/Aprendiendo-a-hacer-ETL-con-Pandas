# ğŸ¼ MÃ³dulo 3 : Datos de Texto  ğŸ”„
---

# ğŸ§¹ ManipulaciÃ³n de Texto en Pandas y TokenizaciÃ³n

## ğŸ“Œ Â¿Por quÃ© es importante?

* El texto contiene **informaciÃ³n valiosa**, como valoraciones o descripciones que pueden influir en variables como el precio.
* Procesar texto requiere **preparaciÃ³n previa**: limpieza, normalizaciÃ³n y tokenizaciÃ³n.

---

## ğŸ§ª ManipulaciÃ³n de Texto en Pandas

### ğŸ”  ConversiÃ³n a minÃºsculas

Para evitar inconsistencias como "Bonito" vs "bonito", se convierte el texto a minÃºsculas.

```python
df['descripcion'] = df['descripcion'].str.lower()
```

### ğŸ“Œ `.str` y `.lower()`

| MÃ©todo     | FunciÃ³n                                                                 |
| ---------- | ----------------------------------------------------------------------- |
| `.str`     | Accede a mÃ©todos de cadenas en columnas tipo texto (`object`) en Pandas |
| `.lower()` | Convierte todo el texto a minÃºsculas                                    |

---

## âœ‚ï¸ TokenizaciÃ³n: Dividir texto en partes

### âœ… Â¿QuÃ© es tokenizar?

Es dividir un texto en **unidades mÃ¡s pequeÃ±as** llamadas *tokens* (como palabras, caracteres o frases).

---

## ğŸ§° Pasos para Tokenizar un Texto

### 1. Obtener el texto

```python
texto = "Este es un ejemplo de texto para tokenizar."
```

---

### 2. Limpieza del texto (recomendado)

```python
import re

texto = "Â¡Hola! Este es un ejemplo... con sÃ­mbolos."
texto = re.sub(r'[^\w\s]', '', texto)  # Quitar puntuaciÃ³n
texto = texto.lower()  # MinÃºsculas
```

ğŸ” Resultado: `'hola este es un ejemplo con sÃ­mbolos'`

---

### 3. TokenizaciÃ³n por palabras

```python
tokens = texto.split()
print(tokens)
# ['hola', 'este', 'es', 'un', 'ejemplo', 'con', 'sÃ­mbolos']
```

---

### 4. NormalizaciÃ³n

#### ğŸ”¸ Stemming (RaÃ­ces de palabras)

```python
from nltk.stem import PorterStemmer
stemmer = PorterStemmer()
stemmer.stem("running")  # 'run'
```

#### ğŸ”¸ LemmatizaciÃ³n (Forma base)

```python
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
lemmatizer.lemmatize("better")  # 'good'
```

---

### 5. Eliminar Stop Words (palabras comunes)

```python
from nltk.corpus import stopwords
stopwords.words('spanish')  # ['de', 'la', 'que', ...]
```

---

## ğŸ§  Diferencia clave: `apply` vs `applymap`

| MÃ©todo        | Aplica funciÃ³n a...            | Ideal para...            |
| ------------- | ------------------------------ | ------------------------ |
| `.apply()`    | Cada valor de una **Serie**    | Una sola columna         |
| `.applymap()` | Cada valor de un **DataFrame** | Varias columnas a la vez |

---

## ğŸ’¡ Ejemplos rÃ¡pidos

### â• `apply()` â€“ elevar al cuadrado

```python
s = pd.Series([1, 2, 3])
s.apply(lambda x: x**2)
```

### â• `applymap()` â€“ sumar 10 a cada valor

```python
df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
df.applymap(lambda x: x + 10)
```

---
## ğŸ§  Â¿QuÃ© son las Expresiones Regulares (Regex)?

**Regex (Regular Expressions)** son patrones que se utilizan para buscar, extraer o reemplazar texto dentro de cadenas. Son una herramienta esencial para **limpiar, normalizar o validar** texto en tareas de anÃ¡lisis de datos, especialmente cuando los datos provienen de fuentes no estructuradas como formularios, correos o redes sociales.

---

## ğŸ“Œ Â¿Para quÃ© sirven en ciencia de datos?

* **Limpieza de texto** (eliminaciÃ³n de sÃ­mbolos, puntuaciÃ³n, etiquetas HTML, etc.)
* **ExtracciÃ³n de patrones** (como emails, fechas, precios, etc.)
* **ValidaciÃ³n de formatos** (por ejemplo, verificar que una cadena sea un cÃ³digo postal vÃ¡lido)
* **ClasificaciÃ³n** (spam/no spam, sentimientos, categorÃ­as)

---

## ğŸ§ª Metacaracteres comunes en Regex

| SÃ­mbolo | Significado                                                  |                   |      |
| ------- | ------------------------------------------------------------ | ----------------- | ---- |
| `.`     | Cualquier carÃ¡cter (excepto salto de lÃ­nea)                  |                   |      |
| `*`     | Cero o mÃ¡s repeticiones                                      |                   |      |
| `+`     | Una o mÃ¡s repeticiones                                       |                   |      |
| `?`     | Cero o una repeticiÃ³n                                        |                   |      |
| `[]`    | Conjunto de caracteres (ej: `[abc]`)                         |                   |      |
| `[^]`   | NegaciÃ³n del conjunto (ej: `[^abc]`)                         |                   |      |
| `()`    | AgrupaciÃ³n de patrones                                       |                   |      |
| \`      | \`                                                           | O lÃ³gico (ej: \`a | b\`) |
| `\`     | Escape de carÃ¡cter especial (ej: `\.` para un punto literal) |                   |      |
| `^`     | Inicio de lÃ­nea                                              |                   |      |
| `$`     | Fin de lÃ­nea                                                 |                   |      |

---

## ğŸ›  MÃ©todos clave en Python/Pandas para manipulaciÃ³n de texto

### 1. `.str.replace()` en Pandas

Permite reemplazar texto en una columna entera.

**Ejemplo bÃ¡sico:**

```python
df['columna'] = df['columna'].str.replace('malo', 'bueno')
```

**Ejemplo con regex:**

```python
df['columna'] = df['columna'].str.replace(r'\d+', '', regex=True)  # Elimina todos los nÃºmeros
```

---

### 2. `.str.strip()`

Elimina espacios en blanco al principio y al final de una cadena.

```python
texto = "  hola mundo  "
print(texto.strip())  # â†’ "hola mundo"
```

---

## ğŸ§¹ EliminaciÃ³n de guiones aislados con Regex

Cuando limpiamos texto, es Ãºtil eliminar guiones que **no estÃ¡n entre palabras** (por ejemplo: al final de una lÃ­nea o aislados).

### ğŸ” Regex usada:

```regex
(?<!\w)-(?!\w)
```

### Desglose:

* `(?<!\w)`: Negative lookbehind â†’ **no debe haber una letra o nÃºmero antes del guiÃ³n**
* `-`: Coincide con el guiÃ³n literal
* `(?!\w)`: Negative lookahead â†’ **no debe haber una letra o nÃºmero despuÃ©s del guiÃ³n**

**Ejemplo en Pandas:**

```python
df['columna'] = df['columna'].str.replace(r'(?<!\w)-(?!\w)', '', regex=True).str.strip()
```

---

## ğŸ”¤ TokenizaciÃ³n de Texto

Es el proceso de **dividir texto en unidades (tokens)** como palabras o frases.

**Ejemplo en Python:**

```python
texto = "Hola mundo, esto es NLP"
tokens = texto.lower().split()
print(tokens)  # ['hola', 'mundo,', 'esto', 'es', 'nlp']
```

---

## ğŸ§° Limpieza de texto avanzada con `re` (mÃ³dulo de expresiones regulares de Python)

### Ejemplo completo:

```python
import re

texto = "Â¡Hola! Este es un ejemplo - con sÃ­mbolos y nÃºmeros 123."

# Eliminar caracteres especiales
texto = re.sub(r'[^\w\s]', '', texto)   # â†’ 'Hola Este es un ejemplo  con sÃ­mbolos y nÃºmeros 123'

# Convertir a minÃºsculas
texto = texto.lower()

# Eliminar nÃºmeros
texto = re.sub(r'\d+', '', texto)       # â†’ 'hola este es un ejemplo  con sÃ­mbolos y nÃºmeros '

# Eliminar espacios mÃºltiples
texto = re.sub(r'\s+', ' ', texto).strip()

print(texto)  # â†’ 'hola este es un ejemplo con sÃ­mbolos y nÃºmeros'
```

---

## ğŸš« Stop Words

Son palabras que aparecen frecuentemente pero no aportan valor al anÃ¡lisis (como â€œelâ€, â€œdeâ€, â€œporâ€, â€œconâ€).

**Ejemplo con NLTK:**

```python
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk
nltk.download('stopwords')
nltk.download('punkt')

texto = "Este es un ejemplo de texto con stop words"
palabras = word_tokenize(texto.lower())
limpio = [palabra for palabra in palabras if palabra not in stopwords.words('spanish')]

print(limpio)  # â†’ ['ejemplo', 'texto', 'stop', 'words']
```

---

## ğŸ§± Conceptos clave resumidos

| Concepto             | DescripciÃ³n                                          |
| -------------------- | ---------------------------------------------------- |
| **TokenizaciÃ³n**     | Dividir texto en unidades (palabras, frases, etc.)   |
| **Regex**            | PatrÃ³n para buscar, extraer o reemplazar texto       |
| **replace()**        | Reemplaza partes de una cadena                       |
| **strip()**          | Elimina espacios en extremos de una cadena           |
| **Guiones aislados** | Guiones sin letras alrededor (eliminables con regex) |
| **Stop words**       | Palabras vacÃ­as que no aportan valor                 |
| **NormalizaciÃ³n**    | Unificar el texto (minÃºsculas, sin puntuaciÃ³n, etc.) |

---
